{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8793a6cc-474f-46c3-8a57-b263392157a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import seaborn as sns\n",
    "\n",
    "#Evaluation library\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6134870-8f49-4d11-9fe2-710f462cc966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Train Set & Test Set\n",
    "#X_Test, X_train, Y_Test,Y_Train(Understanding Purpose In machine Learning we split tarin set and test set, indep_X, dep_Y, same set we using to split the Input-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0a9fb55-665a-4669-adb6-8c476359c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae822585-0eba-42af-9e5b-9c33e3615beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b770d3e7-9a69-4833-92f2-66d0aa479483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above from Trainset X_Train.shape\n",
    "#60,000-Total count of the Images\n",
    "#28,28-rows and columns of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc480712-4910-46a9-a05c-cd85479f5be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33fa0dc4-e7b6-4e04-a027-1942df949a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above from Testset X_Test.shape\n",
    "#10,000-Total count of the Images\n",
    "#28,28-rows and columns of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9231b1ae-0af0-474d-8db3-5fc3ff143a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c47b1cd-f97f-41b1-92e0-d3c4a62575d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above (x_train.shape(0)-60,000 - Total count of Images\n",
    "#28*28 - rows and colums of each image(Cube box Images it should be converted into Flatenning Images(Is converetd as single line i.e as \"1\")\n",
    "#Here 1 - is the flatenning the Images(i.e-28*28- Matrix Cube box image will be convereted into flatenning Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeca61e6-9224-414b-a325-480d70f443c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7d0c531-f61c-41dd-a03b-6e9b6d9b9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2535afd4-f503-49c4-b7b9-d43b74effbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above info:\n",
    "#X_train = X_train/255\n",
    "#i.e that is 60,000/255 final answer we need to save in the same x_train & sam e for X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4050406b-31a7-4502-aa5c-bf6cc83dacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a model for CNN for Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "729afd0a-94e4-4445-8674-e8eedfb93f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreet\\anaconda3\\envs\\aidl\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4236450-178a-49dc-8a6f-57ec21b1d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here Sequential is One ouput model to give for One Input Model and then input model move further to another Input model\n",
    "#Dense is a neural network of Fully connected\n",
    "#Here, Conv2D is use for Filter is nothing but here channel depth is collected the info\n",
    "#channel depth is collected the information for Enhancing the Images(Enhancing:to increase or improve in value, quality, desirability, or attractiveness)\n",
    "#Dense(128 is Neuron values)\n",
    "#Dense(10 -we are classifying here for example we can classify also 20 here)\n",
    "#Recall understanding purpose, the basics Concepts, In Interview purpose they will check basics\n",
    "#For ex: Here CNN we activation function 'C' relu without string, but in ANN we give under inside the string so we need to recalll the basics concept\n",
    "#Refer #https://keras.io/api/ the basics steps activation function need to recall\n",
    "#Recall the ANN Visual Video from 3 Blue 1 Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b29e995e-9c46-4675-979e-efafa5d479bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8927 - loss: 0.3585\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.9732 - loss: 0.0865\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.9826 - loss: 0.0550\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9871 - loss: 0.0399\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9893 - loss: 0.0328\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.0270\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0220\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0231\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9947 - loss: 0.0165\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14f26f2d350>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://keras.io/api/optimizers/\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f14cb8a6-05cb-4847-853e-afca6dcc5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If Epoch value Increases, Th accuracy value also increases, and Loss value also Decreses\n",
    "#\"Reminder\": Epoch means forward and Backward(i.e- preforward and backward propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21d377bc-ffc6-4308-9ef7-590c92e1e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model for x_test & y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b696c602-8372-4e6f-929f-64ba910a48cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret metric identifier: classification",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aidl\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\aidl\\Lib\\site-packages\\keras\\src\\metrics\\__init__.py:206\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret metric identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret metric identifier: classification"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af6e513f-2bfc-4004-8f50-3914771e768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here X_test is loss, Y_test is Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a607e13-ddd8-4b9c-9e62-0911107074e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_index = 6900\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "predict = x_test[image_index].reshape(28,28)\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a0869-a1e3-472e-b668-e762b34e2516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
